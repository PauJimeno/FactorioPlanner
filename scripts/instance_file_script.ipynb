{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb5ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1ea225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FUNCTION\n",
    "def read_and_collect_json_files(directory):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'instance_to_solve.json':\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    data.append(json.load(f))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0203c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE FUNCTION\n",
    "def write_to_json_file(data, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c457b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE FILES FUNCTION\n",
    "def move_and_rename_files(src_directory, dst_directory):\n",
    "    if not os.path.exists(dst_directory):\n",
    "        os.makedirs(dst_directory)\n",
    "\n",
    "    i = 0\n",
    "    for root, dirs, files in os.walk(src_directory):\n",
    "        for file in files:\n",
    "            if file == 'instance_to_solve.json':\n",
    "                src_file_path = os.path.join(root, file)\n",
    "                dst_file_path = os.path.join(dst_directory, f'instance_to_solve_{i}.json')\n",
    "                shutil.move(src_file_path, dst_file_path)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2fddbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME ITEM NUMBERS\n",
    "def replace_item_flow(solved_dir, item_data_dir):\n",
    "    for solved_file in os.listdir(solved_dir):\n",
    "        if solved_file.startswith('solved_instance') and solved_file.endswith('.json'):\n",
    "            with open(os.path.join(solved_dir, solved_file), 'r') as f:\n",
    "                solved_data = json.load(f)\n",
    "                \n",
    "            if solved_data.get('status') == 'SAT':\n",
    "                item_data_file = 'item_data' + solved_file[len('solved_instance'):-5] + '.json'  # corresponding item_data file\n",
    "                with open(os.path.join(item_data_dir, item_data_file), 'r') as f:\n",
    "                    item_data = json.load(f)\n",
    "                \n",
    "                # replace integers in each sub-list of ITEM_FLOW with corresponding item names\n",
    "                for sublist in solved_data['ITEM_FLOW']:\n",
    "                    for i in range(len(sublist)):\n",
    "                        if sublist[i] == \"0\":\n",
    "                            sublist[i] = \"none\"\n",
    "                        else:\n",
    "                            sublist[i] = item_data.get(str(sublist[i]), sublist[i])\n",
    "                \n",
    "                # write the updated data back to the file\n",
    "                with open(os.path.join(solved_dir, solved_file), 'w') as f:\n",
    "                    json.dump(solved_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5352192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME ASSEMBLER NUMBERS\n",
    "def replace_assembler(solved_dir, assembler_data_dir):\n",
    "    for solved_file in os.listdir(solved_dir):\n",
    "        if solved_file.startswith('solved_instance') and solved_file.endswith('.json'):\n",
    "            with open(os.path.join(solved_dir, solved_file), 'r') as f:\n",
    "                solved_data = json.load(f)\n",
    "                \n",
    "            if solved_data.get('status') == 'SAT':\n",
    "                assembler_data_file = 'assembler_data' + solved_file[len('solved_instance'):-5] + '.json'  # corresponding assembler_data file\n",
    "                with open(os.path.join(assembler_data_dir, assembler_data_file), 'r') as f:\n",
    "                    assembler_data = json.load(f)\n",
    "                \n",
    "                # replace integers in each sub-list of ASSEMBLER with corresponding assembler names\n",
    "                for sublist in solved_data['ASSEMBLER']:\n",
    "                    for i in range(len(sublist)):\n",
    "                        if sublist[i] == \"0\":\n",
    "                            sublist[i] = \"none\"\n",
    "                        else:\n",
    "                            sublist[i] = assembler_data[int(sublist[i])-1]\n",
    "                \n",
    "                for sublist in solved_data['ASSEMBLER_COLLISION']:\n",
    "                    for i in range(len(sublist)):\n",
    "                        if sublist[i] == \"0\":\n",
    "                            sublist[i] = \"none\"\n",
    "                        else:\n",
    "                            sublist[i] = assembler_data[int(sublist[i])-1]\n",
    "                \n",
    "                # write the updated data back to the file\n",
    "                with open(os.path.join(solved_dir, solved_file), 'w') as f:\n",
    "                    json.dump(solved_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba53ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP SPRITE SHEET\n",
    "def crop_sprites(sprite_sheet_path, cols, rows, output_dir):\n",
    "    # Open the sprite sheet\n",
    "    sprite_sheet = Image.open(sprite_sheet_path)\n",
    "\n",
    "    # Calculate the width and height of each sprite\n",
    "    sprite_width = sprite_sheet.width // cols\n",
    "    sprite_height = sprite_sheet.height // rows\n",
    "\n",
    "    # Loop over the sprite sheet and save each sprite\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Calculate the position of the current sprite\n",
    "            left = col * sprite_width\n",
    "            top = row * sprite_height\n",
    "            right = left + sprite_width\n",
    "            bottom = top + sprite_height\n",
    "\n",
    "            # Crop the sprite\n",
    "            sprite = sprite_sheet.crop((left, top, right, bottom))\n",
    "\n",
    "            # Save the sprite\n",
    "            sprite.save(f\"{output_dir}/sprite_{row}_{col}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19f7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_and_write_to_excel(main_folder_path, destination_folder):\n",
    "    # Initialize a dictionary to store the data\n",
    "    data = {\n",
    "        \"Iteration\": [],\n",
    "        \"Optimization Criteria\": [],\n",
    "        \"Status\": [],\n",
    "        \"Solving Time\": []\n",
    "    }\n",
    "\n",
    "    # Function to sort file names based on the numerical part\n",
    "    def sort_key(file_name):\n",
    "        match = re.search(r'\\d+', file_name)\n",
    "        if match:\n",
    "            return int(match.group())\n",
    "        return file_name\n",
    "\n",
    "    # Iterate over the iterations\n",
    "    for iteration in sorted(os.listdir(main_folder_path)):\n",
    "        iteration_path = os.path.join(main_folder_path, iteration)\n",
    "        \n",
    "        # Iterate over the optimization criteria folders\n",
    "        for criteria in sorted(os.listdir(iteration_path)):\n",
    "            criteria_path = os.path.join(iteration_path, criteria)\n",
    "            \n",
    "            # Iterate over the JSON files\n",
    "            for file in sorted(os.listdir(criteria_path), key=sort_key):\n",
    "                if file.endswith(\".json\"):\n",
    "                    file_path = os.path.join(criteria_path, file)\n",
    "                    \n",
    "                    # Open the JSON file and extract the data\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        status = json_data[\"status\"]\n",
    "                        solving_time = json_data[\"solving_time\"]\n",
    "                        \n",
    "                        # Store the data\n",
    "                        data[\"Iteration\"].append(iteration)\n",
    "                        data[\"Optimization Criteria\"].append(criteria)\n",
    "                        data[\"Status\"].append(status)\n",
    "                        data[\"Solving Time\"].append(solving_time)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Write the DataFrame to an Excel file\n",
    "    output_path = os.path.join(destination_folder, \"output2.xlsx\")\n",
    "    df.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "434f0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_instance_data_and_write_to_excel(main_folder_path, destination_folder):\n",
    "    # Initialize a dictionary to store the data\n",
    "    data_output = {\n",
    "        \"instance\": [],\n",
    "        \"height\": [],\n",
    "        \"width\": [],\n",
    "        \"max_recipes\": [],\n",
    "        \"max_items\": [],\n",
    "        \"max_assemblers\": [],\n",
    "        \"input items\": [],\n",
    "        \"input cells\": [],\n",
    "        \"output cells\": [],\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Function to sort file names based on the numerical part\n",
    "    def sort_key(file_name):\n",
    "        match = re.search(r'\\d+', file_name)\n",
    "        if match:\n",
    "            return int(match.group())\n",
    "        return file_name\n",
    "    i = 1\n",
    "    # Iterate over the JSON files\n",
    "    for file in sorted(os.listdir(main_folder_path), key=sort_key):\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(main_folder_path, file)\n",
    "            \n",
    "            # Open the JSON file and extract the data\n",
    "            with open(file_path, \"r\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "                \n",
    "                # Extract the required data\n",
    "                unique_items = set()\n",
    "                for recipe in data['recipes'].values():\n",
    "                    for items in recipe.values():\n",
    "                        for item in items:\n",
    "                            unique_items.add(item[0])\n",
    "\n",
    "                num_unique_items = len(unique_items)\n",
    "                \n",
    "                unique_input_items = set()\n",
    "                for item in data['inOutPos']['IN'].values():\n",
    "                    unique_input_items.add(item['ITEM'])\n",
    "                num_unique_input_items = len(unique_input_items)\n",
    "                \n",
    "                num_recipes = len(data[\"recipes\"])\n",
    "                num_unique_items = len(unique_items)\n",
    "                num_input_cells = len(data[\"inOutPos\"][\"IN\"])\n",
    "                num_output_cells = len(data[\"inOutPos\"][\"OUT\"])\n",
    "                height = data[\"size\"][0]\n",
    "                width = data[\"size\"][1]\n",
    "                \n",
    "                # Store the data\n",
    "                data_output[\"max_recipes\"].append(num_recipes)\n",
    "                data_output[\"max_items\"].append(num_unique_items)\n",
    "                data_output[\"input cells\"].append(num_input_cells)\n",
    "                data_output[\"output cells\"].append(num_output_cells)\n",
    "                data_output[\"input items\"].append(num_unique_input_items)\n",
    "                data_output[\"height\"].append(height)\n",
    "                data_output[\"max_assemblers\"].append((width//3)*(height//3))\n",
    "                data_output[\"width\"].append(width)\n",
    "                data_output[\"instance\"].append(i)\n",
    "                i+=1\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data_output)\n",
    "\n",
    "    # Write the DataFrame to an Excel file\n",
    "    output_path = os.path.join(destination_folder, \"instance_values.xlsx\")\n",
    "    df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f9c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP ALL INSTANCES\n",
    "directory = 'E:\\TFG\\solved_instances\\instances_to_solve'  # replace with your directory\n",
    "output_file = 'all_instances.json'  # replace with your output file name\n",
    "data = read_and_collect_json_files(directory)\n",
    "write_to_json_file(data, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31661bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE ALL INSTACES RENAMED\n",
    "src_directory = 'E:\\TFG\\solved_instances\\instances_to_solve'  # replace with your source directory\n",
    "dst_directory = 'E:\\TFG\\solved_instances\\instances_to_solve\\instances'  # replace with your destination directory\n",
    "move_and_rename_files(src_directory, dst_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df591fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE ITEM NAMES\n",
    "solved_dir = 'E:\\TFG\\solved_instances\\instances_to_solve\\solved'  # replace with your solved directory\n",
    "item_data_dir = 'E:\\TFG\\solved_instances\\instances_to_solve\\item_data'  # replace with your item_data directory\n",
    "replace_item_flow(solved_dir, item_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1644b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE ASSEMBLER NAMES\n",
    "solved_dir = 'E:\\\\TFG\\\\solved_instances\\\\instances_to_solve\\\\solved'  # replace with your solved directory\n",
    "assembler_data_dir = 'E:\\\\TFG\\\\solved_instances\\\\instances_to_solve\\\\assembler_data'  # replace with your assembler_data directory\n",
    "replace_assembler(solved_dir, assembler_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "201342a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP IMAGES\n",
    "crop_sprites(\"E:\\\\TFG\\\\factorio_sprites\\\\inserter\\\\hr-inserter-platform.png\", 4, 1, \"E:\\\\TFG\\\\factorio_sprites\\\\inserter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6e9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT TIMES INTO EXCEL\n",
    "extract_data_and_write_to_excel(\"E:\\TFG\\FactorioPlanner\\solved_instances\", \"E:\\TFG\\instance_times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29977d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT INSTANCE DATA TO EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d53965c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "extract_instance_data_and_write_to_excel(\"E:\\TFG\\solved_instances\\instances_to_solve\\instances\", \"E:\\TFG\\instance_times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
